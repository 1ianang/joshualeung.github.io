<!DOCTYPE html>
<html lang="en">
  <head>
    

    
<script>!function(){var e=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,t=localStorage.getItem("use-color-scheme")||"auto";("dark"===t||e&&"light"!==t)&&document.documentElement.classList.toggle("dark",!0)}()</script>
    

<meta charset="utf-8" >

<title>大语言模型原理之 DPO 算法</title>
<meta name="keywords" content="大语言模型原理之 DPO 算法, 击壤而歌">
<meta name="description" content="大语言模型原理之 DPO 算法">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta property="og:title" content="大语言模型原理之 DPO 算法">
<meta property="og:description" content="大语言模型原理之 DPO 算法">

<link rel="shortcut icon" href="/favicon.ico">
<link rel="stylesheet" href="/style/main.css">

  <!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --><link rel="stylesheet" href="/style/simple-lightbox.min.css"><meta name="generator" content="Hexo 7.3.0"></head>
  <body>
    <div id="app" class="main">

<div class="site-header-container">
  <div class="site-header">
    <div class="left">
      <a href="http://orrrrz.github.io">
        <img class="avatar" src="/images/avatar.png" alt="logo" width="32px" height="32px">
      </a>
      <a href="http://orrrrz.github.io">
        <h1 class="site-title">击壤而歌</h1>
      </a>
    </div>
    <div class="right">
        <i class="icon menu-switch icon-menu-outline" ></i>
    </div>
  </div>
</div>

<div class="menu-container" style="height: 0;opacity: 0;">
<nav class="menu-list">
  
    
      <a href="/" class="menu purple-link">
        首页
      </a>
    
  
    
      <a href="/tags" class="menu purple-link">
        标签
      </a>
    
  
    
      <a href="/archives" class="menu purple-link">
        归档
      </a>
    
  
    
      <a href="/about" class="menu purple-link">
        关于
      </a>
    
  
</nav>
</div>



  <div class="content-container">
    <div class="post-detail">
      
      <h2 class="post-title">大语言模型原理之 DPO 算法</h2>
      <div class="post-info post-detail-info">
        <span><i class="icon icon-calendar-outline"></i> 2025-02-07</span>
        
          <span>
          <i class="icon icon-pricetags-outline"></i>
            
              <a href="/tags/DPO/">
              DPO
                
                  ，
                
              </a>
            
              <a href="/tags/RLHF/">
              RLHF
                
                  ，
                
              </a>
            
              <a href="/tags/LLM/">
              LLM
                
                  ，
                
              </a>
            
              <a href="/tags/Direct-Preference-Optimization/">
              Direct Preference Optimization
                
              </a>
            
          </span>
        
      </div>
      <div class="post-content-wrapper">
        <div class="post-content">
          <p>2023年5月， 由Standford在论文 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.18290">Direct Preference Optimization: Your Language Model is Secretly a Reward Model</a> 中提出。 作为<a target="_blank" rel="noopener" href="https://pub.towardsai.net/reinforcement-learning-from-human-feedback-rlhf-f88687d5402e">Reinforcement Learning from Human Feedback (RLHF)</a> 的直接替代方案， DPO 不需要单独训练一个奖励模型， 也去除了冗余、耗时的人工标注环节， 因此在问世之后受到了极大的欢迎 。 </p>
<p><a class="simple-lightbox" target="_blank" rel="noopener" href="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AqKOT0pxzi5kOgiobb-Fvg.png"><img   src="/images/loading.svg" data-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AqKOT0pxzi5kOgiobb-Fvg.png"  lazyload></a></p>
<p>DPO 的数据输入格式如下:</p>
<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(prompt, chosen answer, rejected answer)</span><br></pre></td></tr></table></figure>

<p>与RHLF不同的是， 数据集不必基于当前模型的输出构造。 </p>
<p>在微调开始时， 当前LM被复制一份， 并冻结其参数。 因此， 我们有两个模型， 一个是可训练模型(TLM)， 一个是冻结参数模型(FLM)。<br>对于每一条输入样本， TLM和FLM分别对 chosen answer 和 rejected answer 进行打分。 打分由期望输出文本各个token的概率乘积得到 (做对数处理，否则会因精度溢出导致数值不稳定)。 </p>
<p><a class="simple-lightbox" href="/1.1%20LLM%20%E5%8E%9F%E7%90%86-20241110205212808.webp"><img   src="/images/loading.svg" data-src="/1.1%20LLM%20%E5%8E%9F%E7%90%86-20241110205212808.webp"  lazyload></a></p>
<p>得到这4个分数后， 就可以计算loss并用来更新 TLM了。 </p>
<p><a class="simple-lightbox" href="/1.1%20LLM%20%E5%8E%9F%E7%90%86-20241110205438890.webp"><img   src="/images/loading.svg" data-src="/1.1%20LLM%20%E5%8E%9F%E7%90%86-20241110205438890.webp"  lazyload></a></p>
<p>其中， $\beta$是超参数，用来控制TLM与FLM的偏离度(在Zephyr 中, $\beta$  &#x3D; 0.1)。</p>
<p>DPO的优点: 稳定、高效、轻量。 </p>
<p><a class="simple-lightbox" target="_blank" rel="noopener" href="https://sebastianraschka.com/images/LLMs-from-scratch-images/dpo/3.webp?123"><img   src="/images/loading.svg" data-src="https://sebastianraschka.com/images/LLMs-from-scratch-images/dpo/3.webp?123"  lazyload></a><br>这个公式来源于论文， 与上面简化版的公式是等价的。 </p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>[1] <a target="_blank" rel="noopener" href="https://medium.com/@joaolages/direct-preference-optimization-dpo-622fc1f18707">Direct Preference Optimization (DPO)</a></p>

        </div>
          
        <div class="top-div">
          <ol class="top-box"><li class="top-box-item top-box-level-3"><a class="top-box-link" href="#%E5%8F%82%E8%80%83"><span class="top-box-text">参考</span></a></li></ol>
        </div>
          
      </div>
    </div>

    
      <div class="next-post">
        <a class="purple-link" href="/2025/01/29/perspective/on-deepseek-and-export-control/">
          <h3 class="post-title">
            下一篇：Anthropic CEO 谈DeepSeek和出口管制
          </h3>
        </a>
      </div>
    
  </div>


    <div id="gitalk-container"></div>



    <link rel="stylesheet" href="/style/gitalk.min.css"/>
    <script src="/js/gitalk.min.js"></script>
    <script>
        const config = {"clientId":"Ov23ctHktH8663nWo7p3","clientSecret":"17ed39dfe9fd4213784f3600cbb3591c2a2d3180","repository":"orrrrz.github.io","owner":"orrrrz","createIssueManually":false};
        const gitalk = new Gitalk({
            clientID: config.clientId,
            clientSecret: config.clientSecret,
            repo: config.repository,
            owner: config.owner,
            admin: [config.owner],
            id: location.pathname.slice(1, location.pathname.lastIndexOf('/')).substring(0, 49),       // Ensure uniqueness and length less than 50
            distractionFreeMode: false,  // Facebook-like distraction free mode
            createIssueManually: config.createIssueManually ? true : false
        });

        gitalk.render('gitalk-container')

    </script>







<footer>
<div class="site-footer">
  <div class="social-container">
    
      
        <a aria-label="跳转至github" href="https://github.com/orrrrz" target="_blank">
          <i class="icon icon-github"></i>
        </a>
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  </div>
  
    Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> <a href="https://github.com/f-dong/hexo-theme-minimalism" target="_blank">Theme</a>
  
  
  
  
  
  
</div>
</footer>


      </div>
    </div>
    
<script id="hexo-configurations"> window.theme_config = {"image":{"lazyload_enable":true,"photo_zoom":"simple-lightbox"}}; window.is_post = true; </script>

<script src="/js/main.js"></script>


    <script async src="https://www.googletagmanager.com/gtag/js?id=G-BD6SR7X2TB"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-BD6SR7X2TB');
    </script>





  <script src="/js/simple-lightbox.min.js"></script><script>document.addEventListener('DOMContentLoaded', function() {new SimpleLightbox('.post-detail .simple-lightbox', {fileExt: false,captionsData:'alt'});});</script></body>
</html>

