<!DOCTYPE html>
<html lang="en">
  <head>
    

    
<script>!function(){var e=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,t=localStorage.getItem("use-color-scheme")||"auto";("dark"===t||e&&"light"!==t)&&document.documentElement.classList.toggle("dark",!0)}()</script>
    

<meta charset="utf-8" >

<title>RAG中的文档分块策略</title>
<meta name="keywords" content="RAG中的文档分块策略, 击壤而歌">
<meta name="description" content="在基于 DPR (Deep Passage Retrieval) 的 RAG 系统中， Chunking 是离线索引阶段非常重要的环节， 对RAG的最终效果有重要影响。
Chunking 将文档划分为多个易于处理的小块，使得在线检索阶段仅需">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta property="og:title" content="RAG中的文档分块策略">
<meta property="og:description" content="在基于 DPR (Deep Passage Retrieval) 的 RAG 系统中， Chunking 是离线索引阶段非常重要的环节， 对RAG的最终效果有重要影响。
Chunking 将文档划分为多个易于处理的小块，使得在线检索阶段仅需">

<link rel="shortcut icon" href="/favicon.ico">
<link rel="stylesheet" href="/style/main.css">

  <!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --><link rel="stylesheet" href="/style/simple-lightbox.min.css"><meta name="generator" content="Hexo 7.3.0"></head>
  <body>
    <div id="app" class="main">

<div class="site-header-container">
  <div class="site-header">
    <div class="left">
      <a href="http://orrrrz.github.io">
        <img class="avatar" src="/images/avatar.png" alt="logo" width="32px" height="32px">
      </a>
      <a href="http://orrrrz.github.io">
        <h1 class="site-title">击壤而歌</h1>
      </a>
    </div>
    <div class="right">
        <i class="icon menu-switch icon-menu-outline" ></i>
    </div>
  </div>
</div>

<div class="menu-container" style="height: 0;opacity: 0;">
<nav class="menu-list">
  
    
      <a href="/" class="menu purple-link">
        首页
      </a>
    
  
    
      <a href="/tags" class="menu purple-link">
        标签
      </a>
    
  
    
      <a href="/archives" class="menu purple-link">
        归档
      </a>
    
  
    
      <a href="/about" class="menu purple-link">
        关于
      </a>
    
  
</nav>
</div>



  <div class="content-container">
    <div class="post-detail">
      
      <h2 class="post-title">RAG中的文档分块策略</h2>
      <div class="post-info post-detail-info">
        <span><i class="icon icon-calendar-outline"></i> 2025-01-17</span>
        
          <span>
          <i class="icon icon-pricetags-outline"></i>
            
              <a href="/tags/RAG/">
              RAG
                
                  ，
                
              </a>
            
              <a href="/tags/Retrieval-Augmented-Generation/">
              Retrieval Augmented Generation
                
                  ，
                
              </a>
            
              <a href="/tags/Chunking/">
              Chunking
                
              </a>
            
          </span>
        
      </div>
      <div class="post-content-wrapper">
        <div class="post-content">
          <p>在基于 DPR (Deep Passage Retrieval) 的 RAG 系统中， Chunking 是离线索引阶段非常重要的环节， 对RAG的最终效果有重要影响。</p>
<p>Chunking 将文档划分为多个易于处理的小块，使得在线检索阶段仅需返回相关的文档块， 而不是整个文档， 从而避免LLM的上下文窗口限制。然而， 要返回与查询高度相关的文档块， 提前是文档能被合理地分块。否则，有效的信息可能会因为错误的分块而被噪声淹没，或者语义和上下文信息被破坏，这些都会降低检索的有效性。 </p>
<p>文本介绍与Chunking相关的不同策略， 介绍其基本思想、实现细节及使用方式。</p>
<p><a class="simple-lightbox" target="_blank" rel="noopener" href="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sBEoJ2xomZl77X6wUmdOlw.png"><img   src="/images/loading.svg" data-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sBEoJ2xomZl77X6wUmdOlw.png"  alt="文档分块在RAG中的位置" lazyload></a></p>
<h2 id="Chunking策略"><a href="#Chunking策略" class="headerlink" title="Chunking策略"></a>Chunking策略</h2><h3 id="1-固定大小分块-Fixed-size-Chunking"><a href="#1-固定大小分块-Fixed-size-Chunking" class="headerlink" title="1. 固定大小分块 (Fixed-size Chunking)"></a>1. 固定大小分块 (Fixed-size Chunking)</h3><p>这是最简单粗暴的分块策略，不考虑文档的内容和结构，将文档划分成固定大小的文本块。 这里的固定大小， 可以是固定的字符、token、单词或者句子个数。 这种方式实现最简单， 同时缺点也最明显: 很容易损坏语义的完整性和连贯性，粒度越细， 损坏越严重。为了缓解这种情况， 通常会在相邻的chunk间有一定重叠(chunk overlap)，但这在带来一定数据冗余的同时， 仍只能有限挽救分块边界对语义的破坏。 </p>
<p>在固定大小分块策略中， 除了切分的粒度， 分块的大小(chunk_size)及分块重叠的大小(chunk_overlap)也是影响分块效果的重要因素。一般来说， 分块越小， 重叠越大， 检索效果越好(Recall&#x2F;Precision&#x2F;F1等)。 </p>
<p>在 LangChain 中，  可以使用 CharacterTextSplitter 来实现固定字符大小的文档分块。也可以利用 Chonkie 库实现，以下代码实现了固定token数量的文档分块，其中tokenizer使用的是gpt2同款:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> chonkie <span class="keyword">import</span> TokenChunker</span><br><span class="line"></span><br><span class="line">chunker = TokenChunker(</span><br><span class="line">    tokenizer=<span class="string">&quot;gpt2&quot;</span>,  <span class="comment"># Supports string identifiers</span></span><br><span class="line">    chunk_size=<span class="number">16</span>,    <span class="comment"># Maximum tokens per chunk</span></span><br><span class="line">    chunk_overlap=<span class="number">4</span>  <span class="comment"># Overlap between chunks</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">text = <span class="string">&quot;&quot;&quot;In Chinese mythology, there are five islands in the Bohai Sea, inhabited by immortal beings who have discovered the elixir of life. Many have searched for the islands, but no one have yet found them. I came close, however, four years ago this very week, when I travelled deep into the Nevada desert, to go to Burning Man</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">chunks = chunker(text)</span><br><span class="line"><span class="keyword">for</span> i, chunk <span class="keyword">in</span> <span class="built_in">enumerate</span>(chunks):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Chunk <span class="subst">&#123;i&#125;</span> (<span class="subst">&#123;chunk.token_count&#125;</span> tokens): \n<span class="subst">&#123;chunk.text&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>输出:</p>
<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Chunk 0 (16 tokens): </span><br><span class="line">In Chinese mythology, there are five islands in the Bohai Sea, inhabited by</span><br><span class="line">Chunk 1 (16 tokens): </span><br><span class="line"> Sea, inhabited by immortal beings who have discovered the elixir of life. Many</span><br><span class="line">Chunk 2 (16 tokens): </span><br><span class="line"> of life. Many have searched for the islands, but no one have yet found</span><br><span class="line">Chunk 3 (16 tokens): </span><br><span class="line"> one have yet found them. I came close, however, four years ago this</span><br><span class="line">Chunk 4 (16 tokens): </span><br><span class="line"> four years ago this very week, when I travelled deep into the Nevada desert,</span><br><span class="line">Chunk 5 (10 tokens): </span><br><span class="line"> the Nevada desert, to go to Burning Man</span><br></pre></td></tr></table></figure>

<h3 id="2-递归分块"><a href="#2-递归分块" class="headerlink" title="2. 递归分块"></a>2. 递归分块</h3><p>递归分块是对固定大小分块的一种改进， 其基本思想是基于不同优先级的分隔字符， 以层次和迭代的方式对文档进行分割。 如果初始分割的分块不满足对chunk_size的要求，则在不满足要求的分块上做进一步更细粒度的分割， 同时，对较小的相邻分块进行合并。  </p>
<p>LangChain提供了递归分块类 RecursiveCharacterTextSplitter, 默认以 <code>[&quot;\n\n&quot;, &quot;\n&quot;, &quot; &quot;, &quot;&quot;]</code> 作为层次分隔符来对文档进行递归分块。<br>用法如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> RecursiveCharacterTextSplitter</span><br><span class="line"></span><br><span class="line">text_splitter = RecursiveCharacterTextSplitter(</span><br><span class="line">    chunk_size = <span class="number">100</span>,</span><br><span class="line">    chunk_overlap  = <span class="number">0</span>,</span><br><span class="line">    length_function = <span class="built_in">len</span>,</span><br><span class="line">)</span><br><span class="line">text_splitter.split_text(documents)</span><br></pre></td></tr></table></figure>

<h3 id="3-基于文档结构的分块"><a href="#3-基于文档结构的分块" class="headerlink" title="3. 基于文档结构的分块"></a>3. 基于文档结构的分块</h3><p>这种方法利用文档的结构、格式和内容流程来对文档进行分块(不适用于缺乏清晰结构的文档)。</p>
<p>例如， 对于Markdown文件， 以Markdown标记作为分割的边界， 对于 HTML文件， 以段落标记(<code>&lt;p&gt;</code>)作为分割的边界等。 在 LangChain 中提供了针对不同文档类型的分块工具。对于代码， LangChain针对多个编程语言内置了预设的分隔符。例如， 下面的代码演示了如何对Python代码进行分隔:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">PYTHON_CODE = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">def hello_world():</span></span><br><span class="line"><span class="string">    print(&quot;Hello, World!&quot;)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Call the function</span></span><br><span class="line"><span class="string">hello_world()</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看内置分隔符</span></span><br><span class="line">RecursiveCharacterTextSplitter.get_separators_for_language(Language.PYTHON)</span><br><span class="line"></span><br><span class="line">python_splitter = RecursiveCharacterTextSplitter.from_language(</span><br><span class="line">    language=Language.PYTHON, chunk_size=<span class="number">50</span>, chunk_overlap=<span class="number">0</span></span><br><span class="line">)</span><br><span class="line">python_docs = python_splitter.create_documents([PYTHON_CODE])</span><br><span class="line">python_docs</span><br></pre></td></tr></table></figure>
<p>输出:</p>
<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[Document(page_content=&#x27;def hello_world():\n    print(&quot;Hello, World!&quot;)&#x27;),</span><br><span class="line"> Document(page_content=&#x27;# Call the function\nhello_world()&#x27;)]</span><br></pre></td></tr></table></figure>
<p>更多细节见LangChain 文档 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/how_to/code_splitter/">How to split code</a></p>
<p>对于某些特殊的文档结构， 比如表格， 或非文本模态内容如图片、音频与视频， 可以通过LLM对其进行文字总结后再进行分块处理。 </p>
<h3 id="4-语义分块"><a href="#4-语义分块" class="headerlink" title="4. 语义分块"></a>4. 语义分块</h3><p>以上分块策略均涉及通过指定分隔符对文档进行分割， 且通常需要指定块的大小。 语义分块则是以语义上下文的相关性来作为分块边界的依据。 它对文档进行基础分块（比如划分为句子)后， 对每个分块进行 Embedding处理。 然后， 以句子出现的先后次序， 评估当前分块 Embedding 与其前面一定窗口内分块Embedding均值的余弦距离。 在余弦距离大于一定阈值(绝对值、分位数等)的地方进行分割。</p>
<p><a class="simple-lightbox" href="/assets/rag/semantic-chunk-1.webp"><img   src="/images/loading.svg" data-src="/assets/rag/semantic-chunk-1.webp"  lazyload></a></p>
<p>语义分块相比前两种文档分块方式， 无论是性能还是成本都不占优势。 在论文 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2410.13070">Is Semantic Chunking Worth the Computational Cost?</a>中， Renyi Qu等人对其效果以及成本的合理性进行了挑战。 指出语义分块仅在主题多样性较高的拼接数据集中表现较好。 在非合成数据集中， 基于固定大小的分块策略不仅更快、成本更低， 效果也更好。 </p>
<h3 id="5-Agentic-分块"><a href="#5-Agentic-分块" class="headerlink" title="5. Agentic 分块"></a>5. Agentic 分块</h3><p>Agentic 分块算法通过LLM来决定文档块中应该包含哪些信息以及如何得到文档块。 </p>
<p>为了得到初始分块， 它首先利用LLM从原始文本中提取出独立陈述（称为 Propositions, 也有翻译为命题，即文本中的原子表达式， Proposition 封装了一个独特的事实，并以简洁、自包含的自然语言格式呈现, 详见论文<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2312.06648">《Dense X Retrieval: What Retrieval Granularity Should We Use?》</a>) </p>
<p>LangChain示例如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate, FewShotChatMessagePromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_core.pydantic_v1 <span class="keyword">import</span> BaseModel, Field</span><br><span class="line"><span class="keyword">from</span> langchain_groq <span class="keyword">import</span> ChatGroq</span><br><span class="line"></span><br><span class="line"><span class="comment"># Data model</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GeneratePropositions</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;List of all the propositions in a given document&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    propositions: <span class="type">List</span>[<span class="built_in">str</span>] = Field(</span><br><span class="line">        description=<span class="string">&quot;List of propositions (factual, self-contained, and concise information)&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># LLM with function call</span></span><br><span class="line">llm = ChatGroq(model=<span class="string">&quot;llama-3.1-70b-versatile&quot;</span>, temperature=<span class="number">0</span>)</span><br><span class="line">structured_llm= llm.with_structured_output(GeneratePropositions)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Few shot prompting --- We can add more examples to make it good</span></span><br><span class="line">proposition_examples = [</span><br><span class="line">    &#123;<span class="string">&quot;document&quot;</span>: </span><br><span class="line">        <span class="string">&quot;In 1969, Neil Armstrong became the first person to walk on the Moon during the Apollo 11 mission.&quot;</span>, </span><br><span class="line">     <span class="string">&quot;propositions&quot;</span>: </span><br><span class="line">        <span class="string">&quot;[&#x27;Neil Armstrong was an astronaut.&#x27;, &#x27;Neil Armstrong walked on the Moon in 1969.&#x27;, &#x27;Neil Armstrong was the first person to walk on the Moon.&#x27;, &#x27;Neil Armstrong walked on the Moon during the Apollo 11 mission.&#x27;, &#x27;The Apollo 11 mission occurred in 1969.&#x27;]&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">example_proposition_prompt = ChatPromptTemplate.from_messages(</span><br><span class="line">    [</span><br><span class="line">        (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;document&#125;&quot;</span>),</span><br><span class="line">        (<span class="string">&quot;ai&quot;</span>, <span class="string">&quot;&#123;propositions&#125;&quot;</span>),</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">few_shot_prompt = FewShotChatMessagePromptTemplate(</span><br><span class="line">    example_prompt = example_proposition_prompt,</span><br><span class="line">    examples = proposition_examples,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prompt</span></span><br><span class="line">system = <span class="string">&quot;&quot;&quot;Please break down the following text into simple, self-contained propositions. Ensure that each proposition meets the following criteria:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    1. Express a Single Fact: Each proposition should state one specific fact or claim.</span></span><br><span class="line"><span class="string">    2. Be Understandable Without Context: The proposition should be self-contained, meaning it can be understood without needing additional context.</span></span><br><span class="line"><span class="string">    3. Use Full Names, Not Pronouns: Avoid pronouns or ambiguous references; use full entity names.</span></span><br><span class="line"><span class="string">    4. Include Relevant Dates/Qualifiers: If applicable, include necessary dates, times, and qualifiers to make the fact precise.</span></span><br><span class="line"><span class="string">    5. Contain One Subject-Predicate Relationship: Focus on a single subject and its corresponding action or attribute, without conjunctions or multiple clauses.&quot;&quot;&quot;</span></span><br><span class="line">prompt = ChatPromptTemplate.from_messages(</span><br><span class="line">    [</span><br><span class="line">        (<span class="string">&quot;system&quot;</span>, system),</span><br><span class="line">        few_shot_prompt,</span><br><span class="line">        (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;document&#125;&quot;</span>),</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">proposition_generator = prompt | structured_llm</span><br></pre></td></tr></table></figure>

<p>这些独立陈述随后被输入LLM进行评价， 从accuracy, clarity, completeness, and conciseness多个维度进行打分。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Data model</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GradePropositions</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Grade a given proposition on accuracy, clarity, completeness, and conciseness&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    accuracy: <span class="built_in">int</span> = Field(</span><br><span class="line">        description=<span class="string">&quot;Rate from 1-10 based on how well the proposition reflects the original text.&quot;</span></span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    clarity: <span class="built_in">int</span> = Field(</span><br><span class="line">        description=<span class="string">&quot;Rate from 1-10 based on how easy it is to understand the proposition without additional context.&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    completeness: <span class="built_in">int</span> = Field(</span><br><span class="line">        description=<span class="string">&quot;Rate from 1-10 based on whether the proposition includes necessary details (e.g., dates, qualifiers).&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    conciseness: <span class="built_in">int</span> = Field(</span><br><span class="line">        description=<span class="string">&quot;Rate from 1-10 based on whether the proposition is concise without losing important information.&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="comment"># LLM with function call</span></span><br><span class="line">llm = ChatGroq(model=<span class="string">&quot;llama-3.1-70b-versatile&quot;</span>, temperature=<span class="number">0</span>)</span><br><span class="line">structured_llm= llm.with_structured_output(GradePropositions)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prompt</span></span><br><span class="line">evaluation_prompt_template = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Please evaluate the following proposition based on the criteria below:</span></span><br><span class="line"><span class="string">- **Accuracy**: Rate from 1-10 based on how well the proposition reflects the original text.</span></span><br><span class="line"><span class="string">- **Clarity**: Rate from 1-10 based on how easy it is to understand the proposition without additional context.</span></span><br><span class="line"><span class="string">- **Completeness**: Rate from 1-10 based on whether the proposition includes necessary details (e.g., dates, qualifiers).</span></span><br><span class="line"><span class="string">- **Conciseness**: Rate from 1-10 based on whether the proposition is concise without losing important information.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Example:</span></span><br><span class="line"><span class="string">Docs: In 1969, Neil Armstrong became the first person to walk on the Moon during the Apollo 11 mission.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Propositons_1: Neil Armstrong was an astronaut.</span></span><br><span class="line"><span class="string">Evaluation_1: &quot;accuracy&quot;: 10, &quot;clarity&quot;: 10, &quot;completeness&quot;: 10, &quot;conciseness&quot;: 10</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Propositons_2: Neil Armstrong walked on the Moon in 1969.</span></span><br><span class="line"><span class="string">Evaluation_3: &quot;accuracy&quot;: 10, &quot;clarity&quot;: 10, &quot;completeness&quot;: 10, &quot;conciseness&quot;: 10</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Propositons_3: Neil Armstrong was the first person to walk on the Moon.</span></span><br><span class="line"><span class="string">Evaluation_3: &quot;accuracy&quot;: 10, &quot;clarity&quot;: 10, &quot;completeness&quot;: 10, &quot;conciseness&quot;: 10</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Propositons_4: Neil Armstrong walked on the Moon during the Apollo 11 mission.</span></span><br><span class="line"><span class="string">Evaluation_4: &quot;accuracy&quot;: 10, &quot;clarity&quot;: 10, &quot;completeness&quot;: 10, &quot;conciseness&quot;: 10</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Propositons_5: The Apollo 11 mission occurred in 1969.</span></span><br><span class="line"><span class="string">Evaluation_5: &quot;accuracy&quot;: 10, &quot;clarity&quot;: 10, &quot;completeness&quot;: 10, &quot;conciseness&quot;: 10</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Format:</span></span><br><span class="line"><span class="string">Proposition: &quot;&#123;proposition&#125;&quot;</span></span><br><span class="line"><span class="string">Original Text: &quot;&#123;original_text&#125;&quot;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">prompt = ChatPromptTemplate.from_messages(</span><br><span class="line">    [</span><br><span class="line">        (<span class="string">&quot;system&quot;</span>, evaluation_prompt_template),</span><br><span class="line">        (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;proposition&#125;, &#123;original_text&#125;&quot;</span>),</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">proposition_evaluator = prompt | structured_llm</span><br></pre></td></tr></table></figure>

<p> 得分大于一定阈值的独立陈述才会被保留。 </p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Define evaluation categories and thresholds</span></span><br><span class="line">evaluation_categories = [<span class="string">&quot;accuracy&quot;</span>, <span class="string">&quot;clarity&quot;</span>, <span class="string">&quot;completeness&quot;</span>, <span class="string">&quot;conciseness&quot;</span>]</span><br><span class="line">thresholds = &#123;<span class="string">&quot;accuracy&quot;</span>: <span class="number">7</span>, <span class="string">&quot;clarity&quot;</span>: <span class="number">7</span>, <span class="string">&quot;completeness&quot;</span>: <span class="number">7</span>, <span class="string">&quot;conciseness&quot;</span>: <span class="number">7</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Function to evaluate proposition</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate_proposition</span>(<span class="params">proposition, original_text</span>):</span><br><span class="line">    response = proposition_evaluator.invoke(&#123;<span class="string">&quot;proposition&quot;</span>: proposition, <span class="string">&quot;original_text&quot;</span>: original_text&#125;)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Parse the response to extract scores</span></span><br><span class="line">    scores = &#123;<span class="string">&quot;accuracy&quot;</span>: response.accuracy, <span class="string">&quot;clarity&quot;</span>: response.clarity, <span class="string">&quot;completeness&quot;</span>: response.completeness, <span class="string">&quot;conciseness&quot;</span>: response.conciseness&#125;  <span class="comment"># Implement function to extract scores from the LLM response</span></span><br><span class="line">    <span class="keyword">return</span> scores</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check if the proposition passes the quality check</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">passes_quality_check</span>(<span class="params">scores</span>):</span><br><span class="line">    <span class="keyword">for</span> category, score <span class="keyword">in</span> scores.items():</span><br><span class="line">        <span class="keyword">if</span> score &lt; thresholds[category]:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">evaluated_propositions = [] <span class="comment"># Store all the propositions from the document</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Loop through generated propositions and evaluate them</span></span><br><span class="line"><span class="keyword">for</span> idx, proposition <span class="keyword">in</span> <span class="built_in">enumerate</span>(propositions):</span><br><span class="line">    scores = evaluate_proposition(proposition.page_content, doc_splits[proposition.metadata[<span class="string">&#x27;chunk_id&#x27;</span>] - <span class="number">1</span>].page_content)</span><br><span class="line">    <span class="keyword">if</span> passes_quality_check(scores):</span><br><span class="line">        <span class="comment"># Proposition passes quality check, keep it</span></span><br><span class="line">        evaluated_propositions.append(proposition)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># Proposition fails, discard or flag for further review</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;idx+<span class="number">1</span>&#125;</span>) Propostion: <span class="subst">&#123;proposition.page_content&#125;</span> \n Scores: <span class="subst">&#123;scores&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Fail&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>保留下来的独立陈述经过Embedding模型进行编码进入索引。 </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Add to vectorstore</span></span><br><span class="line">vectorstore_propositions = FAISS.from_documents(evaluated_propositions, embedding_model)</span><br><span class="line">retriever_propositions = vectorstore_propositions.as_retriever(</span><br><span class="line">                search_type=<span class="string">&quot;similarity&quot;</span>,</span><br><span class="line">                search_kwargs=&#123;<span class="string">&#x27;k&#x27;</span>: <span class="number">4</span>&#125;, <span class="comment"># number of documents to retrieve</span></span><br><span class="line">            )</span><br></pre></td></tr></table></figure>

<p>代码示例来源于: <a target="_blank" rel="noopener" href="https://github.com/NirDiamant/RAG_Techniques">RAG_Techniques</a></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文介绍了RAG常见的文档分块策略， 介绍了其基础思想和部分实践代码。 在实际应用场景中， 需要综合考虑文档结构、规模、成本与效果因素， 选择合适的分块策略。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a target="_blank" rel="noopener" href="https://medium.com/@anuragmishra_27746five-levels-of-chunking-strategies-in-rag-notes-from-gregs-video-7b735895694d">Five Levels of Chunking Strategies in RAG| Notes from Greg’s Video</a></li>
<li><a target="_blank" rel="noopener" href="https://dev.to/eteimz/understanding-langchains-recursivecharactertextsplitter-2846">Understanding LangChain’s RecursiveCharacterTextSplitter</a></li>
<li><a target="_blank" rel="noopener" href="https://diamantai.substack.com/p/semantic-chunking-improving-ai-information">Semantic Chunking: Improving AI Information Retrieval</a></li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/gsvwS4qlxPiP1yn38SFMIQ">从零开始优化 RAG：7 种 Chunking 方法让你的系统更智能</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/5_Levels_Of_Text_Splitting.ipynb">Greg Kamradt的RAG教程代码</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2312.06648">Dense X Retrieval: What Retrieval Granularity Should We Use?</a></li>
</ol>

        </div>
          
        <div class="top-div">
          <ol class="top-box"><li class="top-box-item top-box-level-2"><a class="top-box-link" href="#Chunking%E7%AD%96%E7%95%A5"><span class="top-box-text">Chunking策略</span></a><ol class="top-box-child"><li class="top-box-item top-box-level-3"><a class="top-box-link" href="#1-%E5%9B%BA%E5%AE%9A%E5%A4%A7%E5%B0%8F%E5%88%86%E5%9D%97-Fixed-size-Chunking"><span class="top-box-text">1. 固定大小分块 (Fixed-size Chunking)</span></a></li><li class="top-box-item top-box-level-3"><a class="top-box-link" href="#2-%E9%80%92%E5%BD%92%E5%88%86%E5%9D%97"><span class="top-box-text">2. 递归分块</span></a></li><li class="top-box-item top-box-level-3"><a class="top-box-link" href="#3-%E5%9F%BA%E4%BA%8E%E6%96%87%E6%A1%A3%E7%BB%93%E6%9E%84%E7%9A%84%E5%88%86%E5%9D%97"><span class="top-box-text">3. 基于文档结构的分块</span></a></li><li class="top-box-item top-box-level-3"><a class="top-box-link" href="#4-%E8%AF%AD%E4%B9%89%E5%88%86%E5%9D%97"><span class="top-box-text">4. 语义分块</span></a></li><li class="top-box-item top-box-level-3"><a class="top-box-link" href="#5-Agentic-%E5%88%86%E5%9D%97"><span class="top-box-text">5. Agentic 分块</span></a></li></ol></li><li class="top-box-item top-box-level-2"><a class="top-box-link" href="#%E6%80%BB%E7%BB%93"><span class="top-box-text">总结</span></a></li><li class="top-box-item top-box-level-2"><a class="top-box-link" href="#%E5%8F%82%E8%80%83"><span class="top-box-text">参考</span></a></li></ol>
        </div>
          
      </div>
    </div>

    
      <div class="next-post">
        <a class="purple-link" href="/2025/01/13/introducing-redtrans/">
          <h3 class="post-title">
            下一篇：Introducing RedTrans - The Missing Translation Tool for REDNote
          </h3>
        </a>
      </div>
    
  </div>


    <div id="gitalk-container"></div>



    <link rel="stylesheet" href="/style/gitalk.min.css"/>
    <script src="/js/gitalk.min.js"></script>
    <script>
        const config = {"clientId":"Ov23ctHktH8663nWo7p3","clientSecret":"17ed39dfe9fd4213784f3600cbb3591c2a2d3180","repository":"orrrrz.github.io","owner":"orrrrz","createIssueManually":false};
        const gitalk = new Gitalk({
            clientID: config.clientId,
            clientSecret: config.clientSecret,
            repo: config.repository,
            owner: config.owner,
            admin: [config.owner],
            id: location.pathname.slice(1, location.pathname.lastIndexOf('/')).substring(0, 49),       // Ensure uniqueness and length less than 50
            distractionFreeMode: false,  // Facebook-like distraction free mode
            createIssueManually: config.createIssueManually ? true : false
        });

        gitalk.render('gitalk-container')

    </script>







<footer>
<div class="site-footer">
  <div class="social-container">
    
      
        <a aria-label="跳转至github" href="https://github.com/orrrrz" target="_blank">
          <i class="icon icon-github"></i>
        </a>
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  </div>
  
    Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> <a href="https://github.com/f-dong/hexo-theme-minimalism" target="_blank">Theme</a>
  
  
  
  
  
  
</div>
</footer>


      </div>
    </div>
    
<script id="hexo-configurations"> window.theme_config = {"image":{"lazyload_enable":true,"photo_zoom":"simple-lightbox"}}; window.is_post = true; </script>

<script src="/js/main.js"></script>


    <script async src="https://www.googletagmanager.com/gtag/js?id=G-BD6SR7X2TB"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-BD6SR7X2TB');
    </script>





  <script src="/js/simple-lightbox.min.js"></script><script>document.addEventListener('DOMContentLoaded', function() {new SimpleLightbox('.post-detail .simple-lightbox', {fileExt: false,captionsData:'alt'});});</script></body>
</html>

